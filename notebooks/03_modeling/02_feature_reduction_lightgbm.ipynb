{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacadaf6",
   "metadata": {},
   "source": [
    "# Feature reduction – LightGBM\n",
    "\n",
    "Ce notebook vise à réduire le nombre de variables utilisées par le modèle LightGBM\n",
    "en s’appuyant sur l’analyse d’importance globale (gain), afin de :\n",
    "\n",
    "- diminuer la complexité du modèle  \n",
    "- accélérer l’entraînement et l’inférence  \n",
    "- améliorer la stabilité  \n",
    "- faciliter l’interprétation métier  \n",
    "\n",
    "La performance est évaluée par validation croisée et comparée au modèle complet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c726f",
   "metadata": {},
   "source": [
    "## Imports + chemins + MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ac93da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD = c:\\Users\\yoann\\Documents\\open classrooms\\projet 8\\livrables\\pret a dépenser\\notebooks\\03_modeling\n",
      "Tracking URI = sqlite:///C:/Users/yoann/Documents/open classrooms/projet 8/livrables/pret a dépenser/mlflow.db\n",
      "Artifacts root (env) = file:///C:/Users/yoann/Documents/open%20classrooms/projet%208/livrables/pret%20a%20d%C3%A9penser/artifacts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "CWD = Path.cwd()\n",
    "PROJECT_ROOT = CWD.parent.parent\n",
    "DB_PATH = (PROJECT_ROOT / \"mlflow.db\").resolve()\n",
    "ARTIFACT_ROOT = (PROJECT_ROOT / \"artifacts\").resolve()\n",
    "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURE_REDUCTION_DIR = PROJECT_ROOT / \"reports\" / \"feature_reduction\"\n",
    "FEATURE_REDUCTION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"sqlite:///{DB_PATH.as_posix()}\"\n",
    "os.environ[\"MLFLOW_ARTIFACT_URI\"] = ARTIFACT_ROOT.as_uri()\n",
    "\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import mlflow  \n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "\n",
    "print(\"CWD =\", CWD)\n",
    "print(\"Tracking URI =\", mlflow.get_tracking_uri())\n",
    "print(\"Artifacts root (env) =\", os.environ[\"MLFLOW_ARTIFACT_URI\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdaa97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/yoann/Documents/open%20classrooms/projet%208/livrables/pret%20a%20d%C3%A9penser/artifacts', creation_time=1771233857159, experiment_id='2', last_update_time=1771233857159, lifecycle_stage='active', name='home_credit_reduction_perimetre', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "from src.modeling.train import train_with_cv\n",
    "from src.modeling.prepare_for_model import prepare_application_for_model\n",
    "from src.tracking import mlflow_tracking\n",
    "\n",
    "EXPERIMENT_NAME = \"home_credit_reduction_perimetre\"\n",
    "exp_id = mlflow_tracking.get_or_create_experiment(EXPERIMENT_NAME, ARTIFACT_ROOT)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "#mlflow ui --backend-store-uri sqlite:///mlflow.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f0111",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084b5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_lgb: (215257, 1656) | y: (215257,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"train_split.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "X_lgb, y = prepare_application_for_model(df, model_type=\"boosting\")\n",
    "print(\"X_lgb:\", X_lgb.shape, \"| y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacbcca",
   "metadata": {},
   "source": [
    "## Chargement feature importance précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abae1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fi loaded: (1656, 3)\n",
      "Importance column used: importance_gain\n"
     ]
    }
   ],
   "source": [
    "FI_DIR = PROJECT_ROOT / \"reports\" / \"feature_importance\"\n",
    "fi_path = FI_DIR / \"lightgbm_feature_importance_full.csv\"\n",
    "fi = pd.read_csv(fi_path)\n",
    "print(\"fi loaded:\", fi.shape)\n",
    "\n",
    "# Robustesse : déterminer la colonne d'importance\n",
    "imp_col = \"importance_gain\" if \"importance_gain\" in fi.columns else [c for c in fi.columns if c.startswith(\"importance_\")][0]\n",
    "print(\"Importance column used:\", imp_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7eb62",
   "metadata": {},
   "source": [
    "## Fonctions utilitaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35469b",
   "metadata": {},
   "source": [
    "### Sélection Top-Nfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9815f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.feature_selection import select_top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4693b85",
   "metadata": {},
   "source": [
    "### Drop features corrélées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9043db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.feature_selection  import drop_correlated_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d5f20",
   "metadata": {},
   "source": [
    "## Parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a77e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"n_estimators\": 150,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 32,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "FEATURE_SIZES = [25, 50, 75, 100, 125, 150]\n",
    "CORR_THRESHOLDS = [None, 0.90, 0.85, 0.80]  # None = pas de filtre corr\n",
    "\n",
    "THRESH_FIXED = 0.5\n",
    "COST_FN = 10\n",
    "COST_FP = 1\n",
    "FBETA_BETA = 3\n",
    "\n",
    "results_reduction = []\n",
    "\n",
    "\n",
    "features_path = FEATURE_REDUCTION_DIR\n",
    "features_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74bbcc",
   "metadata": {},
   "source": [
    "### Réduction du benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced9e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SIZES = [25, 50, 75, 100, 125, 150]\n",
    "CORR_THRESHOLDS = [None, 0.90, 0.85, 0.80]   # None = sans filtrage corr\n",
    "\n",
    "results_reduction = []\n",
    "\n",
    "FEATURE_SIZES = [25, 50, 75, 100, 125, 150]\n",
    "CORR_THRESHOLDS = [None, 0.90, 0.85, 0.80]   # None = sans filtrage corr\n",
    "\n",
    "THRESH_FIXED = 0.5\n",
    "COST_FN = 10\n",
    "COST_FP = 1\n",
    "FBETA_BETA = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5756bd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "NO CORRELATION FILTER\n",
      "==============================\n",
      "\n",
      "===== LightGBM_top25_nocorr =====\n",
      "Top-N shape : (215257, 25)\n",
      "After corr  : (215257, 25) | dropped=0\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top25_nocorr =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5146\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7778 | Recall@0.50=0.7002 | F1@0.50=0.2872 | F3@0.50=0.5438 | Cost=21459\n",
      "   → TN=28537 FP=11039 FN=1042 TP=2434 | fit=2.37s | pred=0.17s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5140\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7649 | Recall@0.50=0.6666 | F1@0.50=0.2757 | F3@0.50=0.5193 | Cost=22607\n",
      "   → TN=28559 FP=11017 FN=1159 TP=2317 | fit=2.13s | pred=0.12s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5145\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7687 | Recall@0.50=0.6742 | F1@0.50=0.2790 | F3@0.50=0.5254 | Cost=22298\n",
      "   → TN=28598 FP=10978 FN=1132 TP=2343 | fit=2.04s | pred=0.14s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5142\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7753 | Recall@0.50=0.6950 | F1@0.50=0.2863 | F3@0.50=0.5406 | Cost=21581\n",
      "   → TN=28595 FP=10981 FN=1060 TP=2415 | fit=1.92s | pred=0.12s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5148\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7650 | Recall@0.50=0.6694 | F1@0.50=0.2785 | F3@0.50=0.5227 | Cost=22390\n",
      "   → TN=28676 FP=10900 FN=1149 TP=2326 | fit=1.88s | pred=0.12s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7704 ± 0.0053\n",
      "Recall@0.50              : 0.6811 ± 0.0138\n",
      "Precision@0.50           : 0.1773 ± 0.0027\n",
      "F1@0.50                  : 0.2813 ± 0.0046\n",
      "F3@0.50                : 0.5304 ± 0.0099\n",
      "Business cost (FN*10+FP*1) : 22067.00 ± 459.38\n",
      "TN/FP/FN/TP (moy)            : 28593.0/10983.0/1108.4/2367.0\n",
      "⏱ Temps total                : 13.33s\n",
      "\n",
      "===== LightGBM_top50_nocorr =====\n",
      "Top-N shape : (215257, 50)\n",
      "After corr  : (215257, 50) | dropped=0\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top50_nocorr =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9735\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7867 | Recall@0.50=0.6997 | F1@0.50=0.2954 | F3@0.50=0.5493 | Cost=20996\n",
      "   → TN=29020 FP=10556 FN=1044 TP=2432 | fit=2.84s | pred=0.15s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9724\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7745 | Recall@0.50=0.6752 | F1@0.50=0.2853 | F3@0.50=0.5303 | Cost=21918\n",
      "   → TN=28948 FP=10628 FN=1129 TP=2347 | fit=3.04s | pred=0.15s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7778 | Recall@0.50=0.6812 | F1@0.50=0.2876 | F3@0.50=0.5348 | Cost=21699\n",
      "   → TN=28957 FP=10619 FN=1108 TP=2367 | fit=2.78s | pred=0.14s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9727\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7853 | Recall@0.50=0.7024 | F1@0.50=0.2957 | F3@0.50=0.5509 | Cost=20934\n",
      "   → TN=28982 FP=10594 FN=1034 TP=2441 | fit=2.78s | pred=0.14s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9741\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7752 | Recall@0.50=0.6705 | F1@0.50=0.2865 | F3@0.50=0.5288 | Cost=21910\n",
      "   → TN=29116 FP=10460 FN=1145 TP=2330 | fit=2.56s | pred=0.14s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7799 ± 0.0051\n",
      "Recall@0.50              : 0.6858 ± 0.0129\n",
      "Precision@0.50           : 0.1840 ± 0.0027\n",
      "F1@0.50                  : 0.2901 ± 0.0045\n",
      "F3@0.50                : 0.5388 ± 0.0094\n",
      "Business cost (FN*10+FP*1) : 21491.40 ± 437.36\n",
      "TN/FP/FN/TP (moy)            : 29004.6/10571.4/1092.0/2383.4\n",
      "⏱ Temps total                : 16.25s\n",
      "\n",
      "===== LightGBM_top75_nocorr =====\n",
      "Top-N shape : (215257, 75)\n",
      "After corr  : (215257, 75) | dropped=0\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top75_nocorr =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15723\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7885 | Recall@0.50=0.7022 | F1@0.50=0.2976 | F3@0.50=0.5521 | Cost=20838\n",
      "   → TN=29088 FP=10488 FN=1035 TP=2441 | fit=3.67s | pred=0.15s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15711\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7754 | Recall@0.50=0.6738 | F1@0.50=0.2859 | F3@0.50=0.5299 | Cost=21908\n",
      "   → TN=29008 FP=10568 FN=1134 TP=2342 | fit=3.63s | pred=0.15s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15716\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7805 | Recall@0.50=0.6835 | F1@0.50=0.2891 | F3@0.50=0.5370 | Cost=21578\n",
      "   → TN=28998 FP=10578 FN=1100 TP=2375 | fit=3.54s | pred=0.15s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15715\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7860 | Recall@0.50=0.7024 | F1@0.50=0.2971 | F3@0.50=0.5518 | Cost=20858\n",
      "   → TN=29058 FP=10518 FN=1034 TP=2441 | fit=3.72s | pred=0.14s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15729\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7753 | Recall@0.50=0.6691 | F1@0.50=0.2865 | F3@0.50=0.5280 | Cost=21932\n",
      "   → TN=29144 FP=10432 FN=1150 TP=2325 | fit=3.86s | pred=0.14s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7811 ± 0.0054\n",
      "Recall@0.50              : 0.6862 ± 0.0140\n",
      "Precision@0.50           : 0.1848 ± 0.0031\n",
      "F1@0.50                  : 0.2912 ± 0.0051\n",
      "F3@0.50                : 0.5398 ± 0.0104\n",
      "Business cost (FN*10+FP*1) : 21422.80 ± 485.75\n",
      "TN/FP/FN/TP (moy)            : 29059.2/10516.8/1090.6/2384.8\n",
      "⏱ Temps total                : 20.66s\n",
      "\n",
      "===== LightGBM_top100_nocorr =====\n",
      "Top-N shape : (215257, 100)\n",
      "After corr  : (215257, 100) | dropped=0\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top100_nocorr =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21348\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7888 | Recall@0.50=0.7045 | F1@0.50=0.3006 | F3@0.50=0.5553 | Cost=20638\n",
      "   → TN=29208 FP=10368 FN=1027 TP=2449 | fit=5.21s | pred=0.15s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21341\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7763 | Recall@0.50=0.6700 | F1@0.50=0.2855 | F3@0.50=0.5278 | Cost=21982\n",
      "   → TN=29064 FP=10512 FN=1147 TP=2329 | fit=5.38s | pred=0.15s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21337\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7804 | Recall@0.50=0.6846 | F1@0.50=0.2917 | F3@0.50=0.5393 | Cost=21417\n",
      "   → TN=29119 FP=10457 FN=1096 TP=2379 | fit=5.62s | pred=0.15s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21343\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7870 | Recall@0.50=0.6976 | F1@0.50=0.2961 | F3@0.50=0.5488 | Cost=20982\n",
      "   → TN=29104 FP=10472 FN=1051 TP=2424 | fit=6.30s | pred=0.19s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21345\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7764 | Recall@0.50=0.6685 | F1@0.50=0.2883 | F3@0.50=0.5290 | Cost=21837\n",
      "   → TN=29259 FP=10317 FN=1152 TP=2323 | fit=7.52s | pred=0.18s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7818 ± 0.0052\n",
      "Recall@0.50              : 0.6850 ± 0.0144\n",
      "Precision@0.50           : 0.1859 ± 0.0034\n",
      "F1@0.50                  : 0.2924 ± 0.0054\n",
      "F3@0.50                : 0.5400 ± 0.0108\n",
      "Business cost (FN*10+FP*1) : 21371.20 ± 506.20\n",
      "TN/FP/FN/TP (moy)            : 29150.8/10425.2/1094.6/2380.8\n",
      "⏱ Temps total                : 32.31s\n",
      "\n",
      "===== LightGBM_top125_nocorr =====\n",
      "Top-N shape : (215257, 125)\n",
      "After corr  : (215257, 125) | dropped=0\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top125_nocorr =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27026\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7886 | Recall@0.50=0.7054 | F1@0.50=0.3003 | F3@0.50=0.5555 | Cost=20644\n",
      "   → TN=29172 FP=10404 FN=1024 TP=2452 | fit=9.09s | pred=0.23s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27021\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7766 | Recall@0.50=0.6729 | F1@0.50=0.2864 | F3@0.50=0.5299 | Cost=21888\n",
      "   → TN=29058 FP=10518 FN=1137 TP=2339 | fit=9.04s | pred=0.22s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27018\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7814 | Recall@0.50=0.6855 | F1@0.50=0.2918 | F3@0.50=0.5398 | Cost=21401\n",
      "   → TN=29105 FP=10471 FN=1093 TP=2382 | fit=9.28s | pred=0.27s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27022\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7875 | Recall@0.50=0.7030 | F1@0.50=0.2983 | F3@0.50=0.5529 | Cost=20784\n",
      "   → TN=29112 FP=10464 FN=1032 TP=2443 | fit=9.05s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 27021\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7770 | Recall@0.50=0.6705 | F1@0.50=0.2887 | F3@0.50=0.5302 | Cost=21789\n",
      "   → TN=29237 FP=10339 FN=1145 TP=2330 | fit=9.14s | pred=0.22s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7822 ± 0.0051\n",
      "Recall@0.50              : 0.6875 ± 0.0146\n",
      "Precision@0.50           : 0.1862 ± 0.0033\n",
      "F1@0.50                  : 0.2931 ± 0.0054\n",
      "F3@0.50                : 0.5417 ± 0.0109\n",
      "Business cost (FN*10+FP*1) : 21301.20 ± 508.26\n",
      "TN/FP/FN/TP (moy)            : 29136.8/10439.2/1086.2/2389.2\n",
      "⏱ Temps total                : 48.13s\n",
      "\n",
      "===== LightGBM_top150_nocorr =====\n",
      "Top-N shape : (215257, 150)\n",
      "After corr  : (215257, 150) | dropped=0\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top150_nocorr =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32537\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7883 | Recall@0.50=0.6962 | F1@0.50=0.2974 | F3@0.50=0.5489 | Cost=20941\n",
      "   → TN=29195 FP=10381 FN=1056 TP=2420 | fit=10.62s | pred=0.23s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32531\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7767 | Recall@0.50=0.6723 | F1@0.50=0.2865 | F3@0.50=0.5297 | Cost=21890\n",
      "   → TN=29076 FP=10500 FN=1139 TP=2337 | fit=10.63s | pred=0.20s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.158787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32530\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7808 | Recall@0.50=0.6820 | F1@0.50=0.2901 | F3@0.50=0.5369 | Cost=21547\n",
      "   → TN=29079 FP=10497 FN=1105 TP=2370 | fit=10.57s | pred=0.20s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32531\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7865 | Recall@0.50=0.7007 | F1@0.50=0.2983 | F3@0.50=0.5518 | Cost=20815\n",
      "   → TN=29161 FP=10415 FN=1040 TP=2435 | fit=7.33s | pred=0.19s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32530\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7771 | Recall@0.50=0.6711 | F1@0.50=0.2893 | F3@0.50=0.5310 | Cost=21742\n",
      "   → TN=29264 FP=10312 FN=1143 TP=2332 | fit=7.06s | pred=0.19s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7819 ± 0.0048\n",
      "Recall@0.50              : 0.6845 ± 0.0121\n",
      "Precision@0.50           : 0.1858 ± 0.0029\n",
      "F1@0.50                  : 0.2923 ± 0.0047\n",
      "F3@0.50                : 0.5397 ± 0.0091\n",
      "Business cost (FN*10+FP*1) : 21387.00 ± 431.45\n",
      "TN/FP/FN/TP (moy)            : 29155.0/10421.0/1096.6/2378.8\n",
      "⏱ Temps total                : 48.97s\n",
      "\n",
      "==============================\n",
      "CORR_THRESHOLD = 0.9\n",
      "==============================\n",
      "\n",
      "===== LightGBM_top25_corr09 =====\n",
      "Top-N shape : (215257, 25)\n",
      "After corr  : (215257, 21) | dropped=4\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top25_corr09 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4137\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7731 | Recall@0.50=0.6913 | F1@0.50=0.2811 | F3@0.50=0.5351 | Cost=21950\n",
      "   → TN=28356 FP=11220 FN=1073 TP=2403 | fit=1.83s | pred=0.13s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4129\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7598 | Recall@0.50=0.6671 | F1@0.50=0.2735 | F3@0.50=0.5180 | Cost=22732\n",
      "   → TN=28414 FP=11162 FN=1157 TP=2319 | fit=1.72s | pred=0.12s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4134\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7645 | Recall@0.50=0.6696 | F1@0.50=0.2756 | F3@0.50=0.5207 | Cost=22566\n",
      "   → TN=28490 FP=11086 FN=1148 TP=2327 | fit=1.98s | pred=0.12s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4131\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7716 | Recall@0.50=0.6944 | F1@0.50=0.2827 | F3@0.50=0.5377 | Cost=21806\n",
      "   → TN=28390 FP=11186 FN=1062 TP=2413 | fit=2.24s | pred=0.13s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4135\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7624 | Recall@0.50=0.6688 | F1@0.50=0.2763 | F3@0.50=0.5208 | Cost=22535\n",
      "   → TN=28551 FP=11025 FN=1151 TP=2324 | fit=2.13s | pred=0.14s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7663 ± 0.0052\n",
      "Recall@0.50              : 0.6783 ± 0.0120\n",
      "Precision@0.50           : 0.1747 ± 0.0020\n",
      "F1@0.50                  : 0.2778 ± 0.0035\n",
      "F3@0.50                : 0.5265 ± 0.0082\n",
      "Business cost (FN*10+FP*1) : 22317.80 ± 368.12\n",
      "TN/FP/FN/TP (moy)            : 28440.2/11135.8/1118.2/2357.2\n",
      "⏱ Temps total                : 11.97s\n",
      "\n",
      "===== LightGBM_top50_corr09 =====\n",
      "Top-N shape : (215257, 50)\n",
      "After corr  : (215257, 42) | dropped=8\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top50_corr09 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7706\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7831 | Recall@0.50=0.7008 | F1@0.50=0.2934 | F3@0.50=0.5485 | Cost=21095\n",
      "   → TN=28881 FP=10695 FN=1040 TP=2436 | fit=2.49s | pred=0.13s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7693\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7709 | Recall@0.50=0.6712 | F1@0.50=0.2811 | F3@0.50=0.5254 | Cost=22218\n",
      "   → TN=28788 FP=10788 FN=1143 TP=2333 | fit=2.69s | pred=0.17s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7700\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7749 | Recall@0.50=0.6823 | F1@0.50=0.2866 | F3@0.50=0.5347 | Cost=21737\n",
      "   → TN=28879 FP=10697 FN=1104 TP=2371 | fit=2.56s | pred=0.16s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7696\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7817 | Recall@0.50=0.6981 | F1@0.50=0.2917 | F3@0.50=0.5460 | Cost=21222\n",
      "   → TN=28844 FP=10732 FN=1049 TP=2426 | fit=3.06s | pred=0.14s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7708\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7732 | Recall@0.50=0.6705 | F1@0.50=0.2834 | F3@0.50=0.5266 | Cost=22087\n",
      "   → TN=28939 FP=10637 FN=1145 TP=2330 | fit=2.58s | pred=0.16s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7768 ± 0.0048\n",
      "Recall@0.50              : 0.6846 ± 0.0129\n",
      "Precision@0.50           : 0.1818 ± 0.0029\n",
      "F1@0.50                  : 0.2873 ± 0.0047\n",
      "F3@0.50                : 0.5362 ± 0.0096\n",
      "Business cost (FN*10+FP*1) : 21671.80 ± 449.44\n",
      "TN/FP/FN/TP (moy)            : 28866.2/10709.8/1096.2/2379.2\n",
      "⏱ Temps total                : 15.75s\n",
      "\n",
      "===== LightGBM_top75_corr09 =====\n",
      "Top-N shape : (215257, 75)\n",
      "After corr  : (215257, 60) | dropped=15\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top75_corr09 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11909\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7844 | Recall@0.50=0.6968 | F1@0.50=0.2936 | F3@0.50=0.5466 | Cost=21141\n",
      "   → TN=28975 FP=10601 FN=1054 TP=2422 | fit=3.49s | pred=0.16s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11895\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7731 | Recall@0.50=0.6723 | F1@0.50=0.2838 | F3@0.50=0.5278 | Cost=22049\n",
      "   → TN=28917 FP=10659 FN=1139 TP=2337 | fit=3.64s | pred=0.16s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11900\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7776 | Recall@0.50=0.6800 | F1@0.50=0.2879 | F3@0.50=0.5344 | Cost=21697\n",
      "   → TN=28999 FP=10577 FN=1112 TP=2363 | fit=3.81s | pred=0.18s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11899\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7848 | Recall@0.50=0.7019 | F1@0.50=0.2946 | F3@0.50=0.5499 | Cost=21003\n",
      "   → TN=28933 FP=10643 FN=1036 TP=2439 | fit=3.68s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11911\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7742 | Recall@0.50=0.6717 | F1@0.50=0.2866 | F3@0.50=0.5294 | Cost=21889\n",
      "   → TN=29097 FP=10479 FN=1141 TP=2334 | fit=3.48s | pred=0.17s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7788 ± 0.0050\n",
      "Recall@0.50              : 0.6845 ± 0.0125\n",
      "Precision@0.50           : 0.1834 ± 0.0025\n",
      "F1@0.50                  : 0.2893 ± 0.0042\n",
      "F3@0.50                : 0.5376 ± 0.0090\n",
      "Business cost (FN*10+FP*1) : 21555.80 ± 412.76\n",
      "TN/FP/FN/TP (moy)            : 28984.2/10591.8/1096.4/2379.0\n",
      "⏱ Temps total                : 20.59s\n",
      "\n",
      "===== LightGBM_top100_corr09 =====\n",
      "Top-N shape : (215257, 100)\n",
      "After corr  : (215257, 78) | dropped=22\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top100_corr09 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15749\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7865 | Recall@0.50=0.7020 | F1@0.50=0.2968 | F3@0.50=0.5514 | Cost=20885\n",
      "   → TN=29051 FP=10525 FN=1036 TP=2440 | fit=4.60s | pred=0.17s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15740\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7732 | Recall@0.50=0.6694 | F1@0.50=0.2837 | F3@0.50=0.5263 | Cost=22090\n",
      "   → TN=28976 FP=10600 FN=1149 TP=2327 | fit=4.28s | pred=0.18s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15736\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7791 | Recall@0.50=0.6829 | F1@0.50=0.2883 | F3@0.50=0.5361 | Cost=21635\n",
      "   → TN=28961 FP=10615 FN=1102 TP=2373 | fit=4.27s | pred=0.17s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15742\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7849 | Recall@0.50=0.6996 | F1@0.50=0.2942 | F3@0.50=0.5485 | Cost=21058\n",
      "   → TN=28958 FP=10618 FN=1044 TP=2431 | fit=3.95s | pred=0.16s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15742\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7753 | Recall@0.50=0.6685 | F1@0.50=0.2856 | F3@0.50=0.5271 | Cost=21992\n",
      "   → TN=29104 FP=10472 FN=1152 TP=2323 | fit=3.99s | pred=0.16s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7798 ± 0.0052\n",
      "Recall@0.50              : 0.6845 ± 0.0143\n",
      "Precision@0.50           : 0.1838 ± 0.0030\n",
      "F1@0.50                  : 0.2897 ± 0.0050\n",
      "F3@0.50                : 0.5379 ± 0.0105\n",
      "Business cost (FN*10+FP*1) : 21532.00 ± 485.15\n",
      "TN/FP/FN/TP (moy)            : 29010.0/10566.0/1096.6/2378.8\n",
      "⏱ Temps total                : 23.52s\n",
      "\n",
      "===== LightGBM_top125_corr09 =====\n",
      "Top-N shape : (215257, 125)\n",
      "After corr  : (215257, 96) | dropped=29\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top125_corr09 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19825\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7858 | Recall@0.50=0.7011 | F1@0.50=0.2962 | F3@0.50=0.5506 | Cost=20931\n",
      "   → TN=29035 FP=10541 FN=1039 TP=2437 | fit=5.47s | pred=0.16s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19818\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7746 | Recall@0.50=0.6692 | F1@0.50=0.2839 | F3@0.50=0.5263 | Cost=22083\n",
      "   → TN=28993 FP=10583 FN=1150 TP=2326 | fit=4.85s | pred=0.21s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19817\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7793 | Recall@0.50=0.6823 | F1@0.50=0.2892 | F3@0.50=0.5365 | Cost=21591\n",
      "   → TN=29025 FP=10551 FN=1104 TP=2371 | fit=5.24s | pred=0.17s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19819\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7850 | Recall@0.50=0.6976 | F1@0.50=0.2948 | F3@0.50=0.5478 | Cost=21057\n",
      "   → TN=29029 FP=10547 FN=1051 TP=2424 | fit=4.68s | pred=0.14s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19821\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7761 | Recall@0.50=0.6719 | F1@0.50=0.2872 | F3@0.50=0.5299 | Cost=21851\n",
      "   → TN=29125 FP=10451 FN=1140 TP=2335 | fit=4.36s | pred=0.15s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7801 ± 0.0045\n",
      "Recall@0.50              : 0.6844 ± 0.0130\n",
      "Precision@0.50           : 0.1842 ± 0.0028\n",
      "F1@0.50                  : 0.2903 ± 0.0046\n",
      "F3@0.50                : 0.5382 ± 0.0096\n",
      "Business cost (FN*10+FP*1) : 21502.60 ± 445.27\n",
      "TN/FP/FN/TP (moy)            : 29041.4/10534.6/1096.8/2378.6\n",
      "⏱ Temps total                : 27.09s\n",
      "\n",
      "===== LightGBM_top150_corr09 =====\n",
      "Top-N shape : (215257, 150)\n",
      "After corr  : (215257, 114) | dropped=36\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top150_corr09 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23781\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7862 | Recall@0.50=0.7002 | F1@0.50=0.2968 | F3@0.50=0.5505 | Cost=20914\n",
      "   → TN=29082 FP=10494 FN=1042 TP=2434 | fit=6.35s | pred=0.19s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23775\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7726 | Recall@0.50=0.6686 | F1@0.50=0.2838 | F3@0.50=0.5260 | Cost=22095\n",
      "   → TN=29001 FP=10575 FN=1152 TP=2324 | fit=7.31s | pred=0.20s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23774\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7801 | Recall@0.50=0.6840 | F1@0.50=0.2904 | F3@0.50=0.5381 | Cost=21498\n",
      "   → TN=29058 FP=10518 FN=1098 TP=2377 | fit=8.05s | pred=0.23s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23774\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7853 | Recall@0.50=0.6987 | F1@0.50=0.2955 | F3@0.50=0.5489 | Cost=21000\n",
      "   → TN=29046 FP=10530 FN=1047 TP=2428 | fit=8.00s | pred=0.21s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23775\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7768 | Recall@0.50=0.6714 | F1@0.50=0.2882 | F3@0.50=0.5303 | Cost=21803\n",
      "   → TN=29193 FP=10383 FN=1142 TP=2333 | fit=8.07s | pred=0.23s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7802 ± 0.0051\n",
      "Recall@0.50              : 0.6846 ± 0.0132\n",
      "Precision@0.50           : 0.1847 ± 0.0029\n",
      "F1@0.50                  : 0.2909 ± 0.0048\n",
      "F3@0.50                : 0.5388 ± 0.0098\n",
      "Business cost (FN*10+FP*1) : 21462.00 ± 454.32\n",
      "TN/FP/FN/TP (moy)            : 29076.0/10500.0/1096.2/2379.2\n",
      "⏱ Temps total                : 40.27s\n",
      "\n",
      "==============================\n",
      "CORR_THRESHOLD = 0.85\n",
      "==============================\n",
      "\n",
      "===== LightGBM_top25_corr085 =====\n",
      "Top-N shape : (215257, 25)\n",
      "After corr  : (215257, 21) | dropped=4\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top25_corr085 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4137\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7731 | Recall@0.50=0.6913 | F1@0.50=0.2811 | F3@0.50=0.5351 | Cost=21950\n",
      "   → TN=28356 FP=11220 FN=1073 TP=2403 | fit=2.75s | pred=0.19s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4129\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7598 | Recall@0.50=0.6671 | F1@0.50=0.2735 | F3@0.50=0.5180 | Cost=22732\n",
      "   → TN=28414 FP=11162 FN=1157 TP=2319 | fit=2.72s | pred=0.16s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4134\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7645 | Recall@0.50=0.6696 | F1@0.50=0.2756 | F3@0.50=0.5207 | Cost=22566\n",
      "   → TN=28490 FP=11086 FN=1148 TP=2327 | fit=2.81s | pred=0.16s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4131\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7716 | Recall@0.50=0.6944 | F1@0.50=0.2827 | F3@0.50=0.5377 | Cost=21806\n",
      "   → TN=28390 FP=11186 FN=1062 TP=2413 | fit=2.63s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4135\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7624 | Recall@0.50=0.6688 | F1@0.50=0.2763 | F3@0.50=0.5208 | Cost=22535\n",
      "   → TN=28551 FP=11025 FN=1151 TP=2324 | fit=2.95s | pred=0.15s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7663 ± 0.0052\n",
      "Recall@0.50              : 0.6783 ± 0.0120\n",
      "Precision@0.50           : 0.1747 ± 0.0020\n",
      "F1@0.50                  : 0.2778 ± 0.0035\n",
      "F3@0.50                : 0.5265 ± 0.0082\n",
      "Business cost (FN*10+FP*1) : 22317.80 ± 368.12\n",
      "TN/FP/FN/TP (moy)            : 28440.2/11135.8/1118.2/2357.2\n",
      "⏱ Temps total                : 15.85s\n",
      "\n",
      "===== LightGBM_top50_corr085 =====\n",
      "Top-N shape : (215257, 50)\n",
      "After corr  : (215257, 42) | dropped=8\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top50_corr085 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7706\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7831 | Recall@0.50=0.7008 | F1@0.50=0.2934 | F3@0.50=0.5485 | Cost=21095\n",
      "   → TN=28881 FP=10695 FN=1040 TP=2436 | fit=3.88s | pred=0.22s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7693\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7709 | Recall@0.50=0.6712 | F1@0.50=0.2811 | F3@0.50=0.5254 | Cost=22218\n",
      "   → TN=28788 FP=10788 FN=1143 TP=2333 | fit=3.91s | pred=0.20s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7700\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7749 | Recall@0.50=0.6823 | F1@0.50=0.2866 | F3@0.50=0.5347 | Cost=21737\n",
      "   → TN=28879 FP=10697 FN=1104 TP=2371 | fit=3.90s | pred=0.16s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7696\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7817 | Recall@0.50=0.6981 | F1@0.50=0.2917 | F3@0.50=0.5460 | Cost=21222\n",
      "   → TN=28844 FP=10732 FN=1049 TP=2426 | fit=4.05s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7708\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7732 | Recall@0.50=0.6705 | F1@0.50=0.2834 | F3@0.50=0.5266 | Cost=22087\n",
      "   → TN=28939 FP=10637 FN=1145 TP=2330 | fit=4.17s | pred=0.15s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7768 ± 0.0048\n",
      "Recall@0.50              : 0.6846 ± 0.0129\n",
      "Precision@0.50           : 0.1818 ± 0.0029\n",
      "F1@0.50                  : 0.2873 ± 0.0047\n",
      "F3@0.50                : 0.5362 ± 0.0096\n",
      "Business cost (FN*10+FP*1) : 21671.80 ± 449.44\n",
      "TN/FP/FN/TP (moy)            : 28866.2/10709.8/1096.2/2379.2\n",
      "⏱ Temps total                : 22.12s\n",
      "\n",
      "===== LightGBM_top75_corr085 =====\n",
      "Top-N shape : (215257, 75)\n",
      "After corr  : (215257, 59) | dropped=16\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top75_corr085 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11654\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7855 | Recall@0.50=0.6985 | F1@0.50=0.2946 | F3@0.50=0.5482 | Cost=21059\n",
      "   → TN=28997 FP=10579 FN=1048 TP=2428 | fit=4.97s | pred=0.15s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11640\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7731 | Recall@0.50=0.6746 | F1@0.50=0.2849 | F3@0.50=0.5297 | Cost=21953\n",
      "   → TN=28933 FP=10643 FN=1131 TP=2345 | fit=5.86s | pred=0.22s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11645\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7778 | Recall@0.50=0.6788 | F1@0.50=0.2874 | F3@0.50=0.5335 | Cost=21743\n",
      "   → TN=28993 FP=10583 FN=1116 TP=2359 | fit=5.55s | pred=0.18s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11644\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7843 | Recall@0.50=0.6973 | F1@0.50=0.2930 | F3@0.50=0.5465 | Cost=21161\n",
      "   → TN=28935 FP=10641 FN=1052 TP=2423 | fit=5.35s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11656\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7741 | Recall@0.50=0.6705 | F1@0.50=0.2856 | F3@0.50=0.5282 | Cost=21961\n",
      "   → TN=29065 FP=10511 FN=1145 TP=2330 | fit=7.08s | pred=0.19s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7790 ± 0.0051\n",
      "Recall@0.50              : 0.6839 ± 0.0117\n",
      "Precision@0.50           : 0.1833 ± 0.0024\n",
      "F1@0.50                  : 0.2891 ± 0.0040\n",
      "F3@0.50                : 0.5372 ± 0.0085\n",
      "Business cost (FN*10+FP*1) : 21575.40 ± 389.30\n",
      "TN/FP/FN/TP (moy)            : 28984.6/10591.4/1098.4/2377.0\n",
      "⏱ Temps total                : 31.02s\n",
      "\n",
      "===== LightGBM_top100_corr085 =====\n",
      "Top-N shape : (215257, 100)\n",
      "After corr  : (215257, 73) | dropped=27\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top100_corr085 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14759\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7863 | Recall@0.50=0.6994 | F1@0.50=0.2955 | F3@0.50=0.5492 | Cost=20996\n",
      "   → TN=29030 FP=10546 FN=1045 TP=2431 | fit=5.34s | pred=0.16s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14749\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7741 | Recall@0.50=0.6700 | F1@0.50=0.2834 | F3@0.50=0.5264 | Cost=22100\n",
      "   → TN=28946 FP=10630 FN=1147 TP=2329 | fit=5.96s | pred=0.22s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14748\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7794 | Recall@0.50=0.6826 | F1@0.50=0.2883 | F3@0.50=0.5360 | Cost=21636\n",
      "   → TN=28970 FP=10606 FN=1103 TP=2372 | fit=6.04s | pred=0.19s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14751\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7845 | Recall@0.50=0.6987 | F1@0.50=0.2949 | F3@0.50=0.5485 | Cost=21032\n",
      "   → TN=29014 FP=10562 FN=1047 TP=2428 | fit=6.13s | pred=0.21s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14752\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 73\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7755 | Recall@0.50=0.6714 | F1@0.50=0.2873 | F3@0.50=0.5297 | Cost=21854\n",
      "   → TN=29142 FP=10434 FN=1142 TP=2333 | fit=6.24s | pred=0.20s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7800 ± 0.0048\n",
      "Recall@0.50              : 0.6844 ± 0.0127\n",
      "Precision@0.50           : 0.1839 ± 0.0029\n",
      "F1@0.50                  : 0.2899 ± 0.0046\n",
      "F3@0.50                : 0.5380 ± 0.0094\n",
      "Business cost (FN*10+FP*1) : 21523.60 ± 441.38\n",
      "TN/FP/FN/TP (moy)            : 29020.4/10555.6/1096.8/2378.6\n",
      "⏱ Temps total                : 32.01s\n",
      "\n",
      "===== LightGBM_top125_corr085 =====\n",
      "Top-N shape : (215257, 125)\n",
      "After corr  : (215257, 91) | dropped=34\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top125_corr085 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18835\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7865 | Recall@0.50=0.6997 | F1@0.50=0.2967 | F3@0.50=0.5502 | Cost=20925\n",
      "   → TN=29091 FP=10485 FN=1044 TP=2432 | fit=6.07s | pred=0.18s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18827\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7745 | Recall@0.50=0.6715 | F1@0.50=0.2843 | F3@0.50=0.5277 | Cost=22030\n",
      "   → TN=28966 FP=10610 FN=1142 TP=2334 | fit=6.90s | pred=0.22s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18829\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7791 | Recall@0.50=0.6852 | F1@0.50=0.2898 | F3@0.50=0.5383 | Cost=21517\n",
      "   → TN=28999 FP=10577 FN=1094 TP=2381 | fit=7.16s | pred=0.22s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18828\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7851 | Recall@0.50=0.7024 | F1@0.50=0.2969 | F3@0.50=0.5517 | Cost=20866\n",
      "   → TN=29050 FP=10526 FN=1034 TP=2441 | fit=7.66s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18831\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7761 | Recall@0.50=0.6734 | F1@0.50=0.2878 | F3@0.50=0.5311 | Cost=21795\n",
      "   → TN=29131 FP=10445 FN=1135 TP=2340 | fit=7.24s | pred=0.26s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7803 ± 0.0048\n",
      "Recall@0.50              : 0.6864 ± 0.0129\n",
      "Precision@0.50           : 0.1847 ± 0.0031\n",
      "F1@0.50                  : 0.2911 ± 0.0050\n",
      "F3@0.50                : 0.5398 ± 0.0097\n",
      "Business cost (FN*10+FP*1) : 21426.60 ± 463.43\n",
      "TN/FP/FN/TP (moy)            : 29047.4/10528.6/1089.8/2385.6\n",
      "⏱ Temps total                : 37.43s\n",
      "\n",
      "===== LightGBM_top150_corr085 =====\n",
      "Top-N shape : (215257, 150)\n",
      "After corr  : (215257, 107) | dropped=43\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top150_corr085 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22281\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7862 | Recall@0.50=0.7014 | F1@0.50=0.2982 | F3@0.50=0.5521 | Cost=20819\n",
      "   → TN=29137 FP=10439 FN=1038 TP=2438 | fit=7.12s | pred=0.19s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22274\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7743 | Recall@0.50=0.6717 | F1@0.50=0.2859 | F3@0.50=0.5290 | Cost=21932\n",
      "   → TN=29054 FP=10522 FN=1141 TP=2335 | fit=7.69s | pred=0.16s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22276\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7802 | Recall@0.50=0.6858 | F1@0.50=0.2906 | F3@0.50=0.5392 | Cost=21460\n",
      "   → TN=29036 FP=10540 FN=1092 TP=2383 | fit=6.29s | pred=0.19s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22273\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7852 | Recall@0.50=0.7013 | F1@0.50=0.2967 | F3@0.50=0.5510 | Cost=20894\n",
      "   → TN=29062 FP=10514 FN=1038 TP=2437 | fit=6.26s | pred=0.21s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22275\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7757 | Recall@0.50=0.6694 | F1@0.50=0.2876 | F3@0.50=0.5289 | Cost=21867\n",
      "   → TN=29199 FP=10377 FN=1149 TP=2326 | fit=5.89s | pred=0.20s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7803 ± 0.0048\n",
      "Recall@0.50              : 0.6859 ± 0.0138\n",
      "Precision@0.50           : 0.1853 ± 0.0030\n",
      "F1@0.50                  : 0.2918 ± 0.0049\n",
      "F3@0.50                : 0.5400 ± 0.0101\n",
      "Business cost (FN*10+FP*1) : 21394.40 ± 468.65\n",
      "TN/FP/FN/TP (moy)            : 29097.6/10478.4/1091.6/2383.8\n",
      "⏱ Temps total                : 35.95s\n",
      "\n",
      "==============================\n",
      "CORR_THRESHOLD = 0.8\n",
      "==============================\n",
      "\n",
      "===== LightGBM_top25_corr08 =====\n",
      "Top-N shape : (215257, 25)\n",
      "After corr  : (215257, 19) | dropped=6\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top25_corr08 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3627\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7727 | Recall@0.50=0.6968 | F1@0.50=0.2831 | F3@0.50=0.5392 | Cost=21751\n",
      "   → TN=28365 FP=11211 FN=1054 TP=2422 | fit=1.82s | pred=0.15s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3619\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7594 | Recall@0.50=0.6602 | F1@0.50=0.2716 | F3@0.50=0.5133 | Cost=22938\n",
      "   → TN=28448 FP=11128 FN=1181 TP=2295 | fit=1.94s | pred=0.14s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3624\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7645 | Recall@0.50=0.6737 | F1@0.50=0.2763 | F3@0.50=0.5232 | Cost=22470\n",
      "   → TN=28446 FP=11130 FN=1134 TP=2341 | fit=1.79s | pred=0.14s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3621\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7702 | Recall@0.50=0.6872 | F1@0.50=0.2796 | F3@0.50=0.5321 | Cost=22087\n",
      "   → TN=28359 FP=11217 FN=1087 TP=2388 | fit=2.09s | pred=0.15s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3625\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7616 | Recall@0.50=0.6650 | F1@0.50=0.2737 | F3@0.50=0.5172 | Cost=22741\n",
      "   → TN=28475 FP=11101 FN=1164 TP=2311 | fit=1.83s | pred=0.14s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7657 ± 0.0050\n",
      "Recall@0.50              : 0.6766 ± 0.0136\n",
      "Precision@0.50           : 0.1740 ± 0.0024\n",
      "F1@0.50                  : 0.2769 ± 0.0041\n",
      "F3@0.50                : 0.5250 ± 0.0095\n",
      "Business cost (FN*10+FP*1) : 22397.40 ± 431.22\n",
      "TN/FP/FN/TP (moy)            : 28418.6/11157.4/1124.0/2351.4\n",
      "⏱ Temps total                : 11.70s\n",
      "\n",
      "===== LightGBM_top50_corr08 =====\n",
      "Top-N shape : (215257, 50)\n",
      "After corr  : (215257, 39) | dropped=11\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top50_corr08 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6988\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7832 | Recall@0.50=0.7014 | F1@0.50=0.2931 | F3@0.50=0.5486 | Cost=21100\n",
      "   → TN=28856 FP=10720 FN=1038 TP=2438 | fit=2.69s | pred=0.16s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6977\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7700 | Recall@0.50=0.6720 | F1@0.50=0.2824 | F3@0.50=0.5267 | Cost=22132\n",
      "   → TN=28844 FP=10732 FN=1140 TP=2336 | fit=2.82s | pred=0.18s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6986\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7746 | Recall@0.50=0.6812 | F1@0.50=0.2862 | F3@0.50=0.5338 | Cost=21777\n",
      "   → TN=28879 FP=10697 FN=1108 TP=2367 | fit=2.66s | pred=0.16s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6982\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7806 | Recall@0.50=0.6990 | F1@0.50=0.2927 | F3@0.50=0.5471 | Cost=21151\n",
      "   → TN=28885 FP=10691 FN=1046 TP=2429 | fit=3.11s | pred=0.19s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6989\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7732 | Recall@0.50=0.6679 | F1@0.50=0.2823 | F3@0.50=0.5246 | Cost=22185\n",
      "   → TN=28931 FP=10645 FN=1154 TP=2321 | fit=2.79s | pred=0.17s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7763 ± 0.0049\n",
      "Recall@0.50              : 0.6843 ± 0.0137\n",
      "Precision@0.50           : 0.1819 ± 0.0029\n",
      "F1@0.50                  : 0.2874 ± 0.0048\n",
      "F3@0.50                : 0.5362 ± 0.0100\n",
      "Business cost (FN*10+FP*1) : 21669.00 ± 465.70\n",
      "TN/FP/FN/TP (moy)            : 28879.0/10697.0/1097.2/2378.2\n",
      "⏱ Temps total                : 16.58s\n",
      "\n",
      "===== LightGBM_top75_corr08 =====\n",
      "Top-N shape : (215257, 75)\n",
      "After corr  : (215257, 54) | dropped=21\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top75_corr08 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10426\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7853 | Recall@0.50=0.6994 | F1@0.50=0.2953 | F3@0.50=0.5491 | Cost=21009\n",
      "   → TN=29017 FP=10559 FN=1045 TP=2431 | fit=3.25s | pred=0.20s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10414\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7721 | Recall@0.50=0.6741 | F1@0.50=0.2842 | F3@0.50=0.5290 | Cost=21997\n",
      "   → TN=28909 FP=10667 FN=1133 TP=2343 | fit=3.92s | pred=0.18s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10421\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7770 | Recall@0.50=0.6829 | F1@0.50=0.2877 | F3@0.50=0.5357 | Cost=21671\n",
      "   → TN=28925 FP=10651 FN=1102 TP=2373 | fit=3.66s | pred=0.17s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10420\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7836 | Recall@0.50=0.7033 | F1@0.50=0.2959 | F3@0.50=0.5515 | Cost=20908\n",
      "   → TN=28978 FP=10598 FN=1031 TP=2444 | fit=3.43s | pred=0.16s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10427\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7741 | Recall@0.50=0.6737 | F1@0.50=0.2878 | F3@0.50=0.5312 | Cost=21795\n",
      "   → TN=29121 FP=10455 FN=1134 TP=2341 | fit=3.37s | pred=0.16s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7784 ± 0.0052\n",
      "Recall@0.50              : 0.6867 ± 0.0125\n",
      "Precision@0.50           : 0.1840 ± 0.0029\n",
      "F1@0.50                  : 0.2902 ± 0.0046\n",
      "F3@0.50                : 0.5393 ± 0.0093\n",
      "Business cost (FN*10+FP*1) : 21476.00 ± 436.33\n",
      "TN/FP/FN/TP (moy)            : 28990.0/10586.0/1089.0/2386.4\n",
      "⏱ Temps total                : 20.27s\n",
      "\n",
      "===== LightGBM_top100_corr08 =====\n",
      "Top-N shape : (215257, 100)\n",
      "After corr  : (215257, 67) | dropped=33\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top100_corr08 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13276\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7863 | Recall@0.50=0.6999 | F1@0.50=0.2964 | F3@0.50=0.5501 | Cost=20938\n",
      "   → TN=29068 FP=10508 FN=1043 TP=2433 | fit=3.69s | pred=0.18s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7729 | Recall@0.50=0.6694 | F1@0.50=0.2838 | F3@0.50=0.5264 | Cost=22087\n",
      "   → TN=28979 FP=10597 FN=1149 TP=2327 | fit=3.61s | pred=0.19s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13269\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7779 | Recall@0.50=0.6826 | F1@0.50=0.2890 | F3@0.50=0.5365 | Cost=21597\n",
      "   → TN=29009 FP=10567 FN=1103 TP=2372 | fit=3.61s | pred=0.16s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7838 | Recall@0.50=0.7039 | F1@0.50=0.2950 | F3@0.50=0.5511 | Cost=20951\n",
      "   → TN=28915 FP=10661 FN=1029 TP=2446 | fit=3.67s | pred=0.16s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7761 | Recall@0.50=0.6685 | F1@0.50=0.2855 | F3@0.50=0.5271 | Cost=21995\n",
      "   → TN=29101 FP=10475 FN=1152 TP=2323 | fit=3.63s | pred=0.19s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7794 ± 0.0049\n",
      "Recall@0.50              : 0.6849 ± 0.0148\n",
      "Precision@0.50           : 0.1839 ± 0.0030\n",
      "F1@0.50                  : 0.2899 ± 0.0050\n",
      "F3@0.50                : 0.5382 ± 0.0107\n",
      "Business cost (FN*10+FP*1) : 21513.60 ± 493.02\n",
      "TN/FP/FN/TP (moy)            : 29014.4/10561.6/1095.2/2380.2\n",
      "⏱ Temps total                : 20.77s\n",
      "\n",
      "===== LightGBM_top125_corr08 =====\n",
      "Top-N shape : (215257, 125)\n",
      "After corr  : (215257, 82) | dropped=43\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top125_corr08 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16587\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 82\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7859 | Recall@0.50=0.6953 | F1@0.50=0.2944 | F3@0.50=0.5465 | Cost=21117\n",
      "   → TN=29049 FP=10527 FN=1059 TP=2417 | fit=4.69s | pred=0.19s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16581\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 82\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7733 | Recall@0.50=0.6735 | F1@0.50=0.2856 | F3@0.50=0.5296 | Cost=21929\n",
      "   → TN=28997 FP=10579 FN=1135 TP=2341 | fit=4.44s | pred=0.19s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16585\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 82\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7781 | Recall@0.50=0.6826 | F1@0.50=0.2883 | F3@0.50=0.5360 | Cost=21638\n",
      "   → TN=28968 FP=10608 FN=1103 TP=2372 | fit=4.04s | pred=0.16s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16584\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 82\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7852 | Recall@0.50=0.7013 | F1@0.50=0.2966 | F3@0.50=0.5509 | Cost=20903\n",
      "   → TN=29053 FP=10523 FN=1038 TP=2437 | fit=4.05s | pred=0.14s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16582\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 82\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7762 | Recall@0.50=0.6765 | F1@0.50=0.2893 | F3@0.50=0.5337 | Cost=21665\n",
      "   → TN=29151 FP=10425 FN=1124 TP=2351 | fit=3.99s | pred=0.15s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7797 ± 0.0050\n",
      "Recall@0.50              : 0.6858 ± 0.0108\n",
      "Precision@0.50           : 0.1845 ± 0.0025\n",
      "F1@0.50                  : 0.2908 ± 0.0040\n",
      "F3@0.50                : 0.5393 ± 0.0080\n",
      "Business cost (FN*10+FP*1) : 21450.40 ± 379.76\n",
      "TN/FP/FN/TP (moy)            : 29043.6/10532.4/1091.8/2383.6\n",
      "⏱ Temps total                : 23.56s\n",
      "\n",
      "===== LightGBM_top150_corr08 =====\n",
      "Top-N shape : (215257, 150)\n",
      "After corr  : (215257, 93) | dropped=57\n",
      "\n",
      "===== Entraînement (benchmark CV) : LightGBM_top150_corr08 =====\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18926\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7866 | Recall@0.50=0.6971 | F1@0.50=0.2960 | F3@0.50=0.5484 | Cost=21004\n",
      "   → TN=29102 FP=10474 FN=1053 TP=2423 | fit=5.14s | pred=0.16s\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18920\n",
      "[LightGBM] [Info] Number of data points in the train set: 172205, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7741 | Recall@0.50=0.6764 | F1@0.50=0.2873 | F3@0.50=0.5322 | Cost=21789\n",
      "   → TN=29037 FP=10539 FN=1125 TP=2351 | fit=6.23s | pred=0.22s\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18926\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7792 | Recall@0.50=0.6777 | F1@0.50=0.2884 | F3@0.50=0.5337 | Cost=21700\n",
      "   → TN=29076 FP=10500 FN=1120 TP=2355 | fit=6.93s | pred=0.20s\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18923\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7845 | Recall@0.50=0.6964 | F1@0.50=0.2934 | F3@0.50=0.5463 | Cost=21150\n",
      "   → TN=28976 FP=10600 FN=1055 TP=2420 | fit=7.08s | pred=0.18s\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[LightGBM] [Info] Number of positive: 13902, number of negative: 158304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18922\n",
      "[LightGBM] [Info] Number of data points in the train set: 172206, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "   → AUC=0.7757 | Recall@0.50=0.6737 | F1@0.50=0.2876 | F3@0.50=0.5311 | Cost=21802\n",
      "   → TN=29114 FP=10462 FN=1134 TP=2341 | fit=7.47s | pred=0.20s\n",
      "\n",
      "===== Résultats finaux (CV) =====\n",
      "AUC                         : 0.7800 ± 0.0048\n",
      "Recall@0.50              : 0.6842 ± 0.0103\n",
      "Precision@0.50           : 0.1844 ± 0.0021\n",
      "F1@0.50                  : 0.2906 ± 0.0035\n",
      "F3@0.50                : 0.5383 ± 0.0075\n",
      "Business cost (FN*10+FP*1) : 21489.00 ± 341.36\n",
      "TN/FP/FN/TP (moy)            : 29061.0/10515.0/1097.4/2378.0\n",
      "⏱ Temps total                : 35.18s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for corr_th in CORR_THRESHOLDS:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"NO CORRELATION FILTER\" if corr_th is None else f\"CORR_THRESHOLD = {corr_th}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for top_n in FEATURE_SIZES:\n",
    "        label = \"nocorr\" if corr_th is None else f\"corr{str(corr_th).replace('.','')}\"\n",
    "        run_name = f\"LightGBM_top{top_n}_{label}\"\n",
    "        print(f\"\\n===== {run_name} =====\")\n",
    "\n",
    "        # 1) Top-N\n",
    "        X_top = select_top_features(X_lgb, fi, top_n, importance_col=imp_col)\n",
    "        print(\"Top-N shape :\", X_top.shape)\n",
    "\n",
    "        # 2) Corr filter (optionnel, uniquement numérique/bool)\n",
    "        if corr_th is None:\n",
    "            X_corr = X_top.copy()\n",
    "            to_drop = []\n",
    "        else:\n",
    "            X_corr, to_drop, _ = drop_correlated_features(X_top, threshold=corr_th)\n",
    "\n",
    "        print(f\"After corr  : {X_corr.shape} | dropped={len(to_drop)}\")\n",
    "\n",
    "        # 3) Sauvegarde locale des features gardées / droppées\n",
    "        keep_file = features_path / f\"kept_features_top{top_n}_{label}.txt\"\n",
    "        keep_file.write_text(\"\\n\".join(X_corr.columns.tolist()), encoding=\"utf-8\")\n",
    "\n",
    "        if corr_th is not None and len(to_drop) > 0:\n",
    "            drop_file = features_path / f\"dropped_features_top{top_n}_{label}.txt\"\n",
    "            drop_file.write_text(\"\\n\".join(to_drop), encoding=\"utf-8\")\n",
    "\n",
    "        # 4) CV run (MLflow géré dans train_with_cv)\n",
    "        model_lgb = LGBMClassifier(**params_lgb)\n",
    "        res = train_with_cv(\n",
    "            model=model_lgb,\n",
    "            model_name=run_name,\n",
    "            X=X_corr,\n",
    "            y=y,\n",
    "            model_type=\"boosting\",\n",
    "            threshold=THRESH_FIXED,\n",
    "            n_splits=5,\n",
    "            random_state=42,\n",
    "            log_fold_metrics=True,\n",
    "            cost_fn=COST_FN,\n",
    "            cost_fp=COST_FP,\n",
    "            fbeta_beta=FBETA_BETA,\n",
    "        )\n",
    "\n",
    "        # 5) Meta infos (pour tableau final)\n",
    "        res[\"model\"] = run_name  # pour être sûr d'avoir le nom complet\n",
    "        res[\"top_n\"] = int(top_n)\n",
    "        res[\"corr_threshold\"] = np.nan if corr_th is None else float(corr_th)\n",
    "        res[\"n_features_after_corr\"] = int(X_corr.shape[1])\n",
    "        res[\"dropped_corr\"] = int(len(to_drop))\n",
    "        results_reduction.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c01c2e",
   "metadata": {},
   "source": [
    "## baseline  lightGBM pour comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8beacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline added: 835f4e494920416797ac8122cf3003ec\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[\"home_credit_benchmarking\"],\n",
    "    filter_string=\"tags.phase = 'benchmark_baseline' and tags.model_name = 'LightGBM'\",\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    ")\n",
    "\n",
    "if runs.empty:\n",
    "    raise ValueError(\"Aucun run MLflow trouvé pour phase=benchmark_baseline et model_name=LightGBM\")\n",
    "\n",
    "r = runs.iloc[0]\n",
    "\n",
    "baseline = {\n",
    "    \"run_id\": r[\"run_id\"],\n",
    "    \"model\": \"LightGBM_full\",\n",
    "\n",
    "    \"auc_mean\": float(r.get(\"metrics.auc_mean\", np.nan)),\n",
    "    \"auc_std\": float(r.get(\"metrics.auc_std\", np.nan)),\n",
    "\n",
    "    \"recall_mean_fixed_threshold\": float(r.get(\"metrics.recall_mean_fixed_threshold\", np.nan)),\n",
    "    \"recall_std_fixed_threshold\": float(r.get(\"metrics.recall_std_fixed_threshold\", np.nan)),\n",
    "\n",
    "    \"precision_mean_fixed_threshold\": float(r.get(\"metrics.precision_mean_fixed_threshold\", np.nan)),\n",
    "    \"precision_std_fixed_threshold\": float(r.get(\"metrics.precision_std_fixed_threshold\", np.nan)),\n",
    "\n",
    "    \"f1_mean_fixed_threshold\": float(r.get(\"metrics.f1_mean_fixed_threshold\", np.nan)),\n",
    "    \"f1_std_fixed_threshold\": float(r.get(\"metrics.f1_std_fixed_threshold\", np.nan)),\n",
    "\n",
    "    \"fbeta_3_mean_fixed_threshold\": float(r.get(\"metrics.fbeta_3_mean_fixed_threshold\", np.nan)),\n",
    "    \"fbeta_3_std_fixed_threshold\": float(r.get(\"metrics.fbeta_3_std_fixed_threshold\", np.nan)),\n",
    "\n",
    "    \"business_cost_mean_fixed_threshold\": float(r.get(\"metrics.business_cost_mean_fixed_threshold\", np.nan)),\n",
    "    \"business_cost_std_fixed_threshold\": float(r.get(\"metrics.business_cost_std_fixed_threshold\", np.nan)),\n",
    "\n",
    "    \"threshold\": float(r.get(\"tags.threshold_fixed\", 0.5)),\n",
    "    \"time_sec\": float(r.get(\"metrics.train_time_sec\", np.nan)),\n",
    "\n",
    "    \"top_n\": int(X_lgb.shape[1]),\n",
    "    \"corr_threshold\": np.nan,\n",
    "    \"n_features_after_corr\": int(X_lgb.shape[1]),\n",
    "    \"dropped_corr\": 0,\n",
    "}\n",
    "\n",
    "results_reduction.append(baseline)\n",
    "print(\"Baseline added:\", baseline[\"run_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b97c8d",
   "metadata": {},
   "source": [
    "## Tableau comparatif final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b1a7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top_n</th>\n",
       "      <th>corr_threshold</th>\n",
       "      <th>n_features_after_corr</th>\n",
       "      <th>dropped_corr</th>\n",
       "      <th>business_cost</th>\n",
       "      <th>business_cost_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>f3</th>\n",
       "      <th>f3_std</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_top125_nocorr</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>21301.2</td>\n",
       "      <td>508.261901</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.014614</td>\n",
       "      <td>0.186234</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.293072</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.541670</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.782206</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>48.133787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_full</td>\n",
       "      <td>1656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>21311.4</td>\n",
       "      <td>456.538542</td>\n",
       "      <td>0.653852</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.196677</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.530527</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.782745</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>522.616138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_top100_nocorr</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>21371.2</td>\n",
       "      <td>506.202094</td>\n",
       "      <td>0.685043</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.292446</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.540042</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>32.312829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_top150_nocorr</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>21387.0</td>\n",
       "      <td>431.447332</td>\n",
       "      <td>0.684468</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.185844</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.781873</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>48.967610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_top150_corr085</td>\n",
       "      <td>150</td>\n",
       "      <td>0.85</td>\n",
       "      <td>107</td>\n",
       "      <td>43</td>\n",
       "      <td>21394.4</td>\n",
       "      <td>468.647671</td>\n",
       "      <td>0.685907</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>0.185324</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.291803</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.540031</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.780311</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>35.949725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_top75_nocorr</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>21422.8</td>\n",
       "      <td>485.753188</td>\n",
       "      <td>0.686194</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>0.184836</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.291225</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.539778</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.781134</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>20.660311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_top125_corr085</td>\n",
       "      <td>125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>91</td>\n",
       "      <td>34</td>\n",
       "      <td>21426.6</td>\n",
       "      <td>463.434397</td>\n",
       "      <td>0.686425</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.184723</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.291106</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.539810</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.780263</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>37.433130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM_top125_corr08</td>\n",
       "      <td>125</td>\n",
       "      <td>0.80</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>21450.4</td>\n",
       "      <td>379.764980</td>\n",
       "      <td>0.685849</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.184544</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.290831</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.539336</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>0.779741</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>23.562577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_top150_corr09</td>\n",
       "      <td>150</td>\n",
       "      <td>0.90</td>\n",
       "      <td>114</td>\n",
       "      <td>36</td>\n",
       "      <td>21462.0</td>\n",
       "      <td>454.315749</td>\n",
       "      <td>0.684583</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.184724</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.290940</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.538784</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.780223</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>40.269654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM_top75_corr08</td>\n",
       "      <td>75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>21476.0</td>\n",
       "      <td>436.334734</td>\n",
       "      <td>0.686655</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.183956</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.290172</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.539279</td>\n",
       "      <td>0.009271</td>\n",
       "      <td>0.778421</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>20.272368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM_top150_corr08</td>\n",
       "      <td>150</td>\n",
       "      <td>0.80</td>\n",
       "      <td>93</td>\n",
       "      <td>57</td>\n",
       "      <td>21489.0</td>\n",
       "      <td>341.360806</td>\n",
       "      <td>0.684238</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.184435</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.290551</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.538346</td>\n",
       "      <td>0.007451</td>\n",
       "      <td>0.780007</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>35.184581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_top50_nocorr</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>21491.4</td>\n",
       "      <td>437.361910</td>\n",
       "      <td>0.685791</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>0.183970</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.290112</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.538811</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>16.252551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_top125_corr09</td>\n",
       "      <td>125</td>\n",
       "      <td>0.90</td>\n",
       "      <td>96</td>\n",
       "      <td>29</td>\n",
       "      <td>21502.6</td>\n",
       "      <td>445.274567</td>\n",
       "      <td>0.684410</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.184190</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.290262</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.538234</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.780149</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>27.088667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM_top100_corr08</td>\n",
       "      <td>100</td>\n",
       "      <td>0.80</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>21513.6</td>\n",
       "      <td>493.015862</td>\n",
       "      <td>0.684871</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.183902</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.289945</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.538241</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.779401</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>20.772032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_top100_corr085</td>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "      <td>21523.6</td>\n",
       "      <td>441.376755</td>\n",
       "      <td>0.684410</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.183895</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.289895</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.537980</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.779950</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>32.013798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_top100_corr09</td>\n",
       "      <td>100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>485.151110</td>\n",
       "      <td>0.684468</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.183754</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.289725</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.537891</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.779805</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>23.523989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM_top75_corr09</td>\n",
       "      <td>75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>21555.8</td>\n",
       "      <td>412.759688</td>\n",
       "      <td>0.684526</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.183403</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.289293</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.537621</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.778823</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>20.586214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_top75_corr085</td>\n",
       "      <td>75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>21575.4</td>\n",
       "      <td>389.295569</td>\n",
       "      <td>0.683950</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.183283</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.289094</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.537201</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.778979</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>31.016258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_top50_corr08</td>\n",
       "      <td>50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>21669.0</td>\n",
       "      <td>465.698186</td>\n",
       "      <td>0.684295</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.287369</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.536175</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.776298</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>16.582872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBM_top50_corr09</td>\n",
       "      <td>50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>21671.8</td>\n",
       "      <td>449.442944</td>\n",
       "      <td>0.684583</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.287256</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.536238</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.776758</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>15.752805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM_top50_corr085</td>\n",
       "      <td>50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>21671.8</td>\n",
       "      <td>449.442944</td>\n",
       "      <td>0.684583</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.287256</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.536238</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.776758</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>22.115781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM_top25_nocorr</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>22067.0</td>\n",
       "      <td>459.380017</td>\n",
       "      <td>0.681072</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.177291</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.530362</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.770351</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>13.334989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LightGBM_top25_corr09</td>\n",
       "      <td>25</td>\n",
       "      <td>0.90</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>22317.8</td>\n",
       "      <td>368.118677</td>\n",
       "      <td>0.678253</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>0.174687</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.277818</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.526478</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.766274</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>11.968090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBM_top25_corr085</td>\n",
       "      <td>25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>22317.8</td>\n",
       "      <td>368.118677</td>\n",
       "      <td>0.678253</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>0.174687</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.277818</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.526478</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.766274</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>15.847871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightGBM_top25_corr08</td>\n",
       "      <td>25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>22397.4</td>\n",
       "      <td>431.221799</td>\n",
       "      <td>0.676584</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>0.174049</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.276871</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.524995</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.765701</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>11.704188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  top_n  corr_threshold  n_features_after_corr  \\\n",
       "0    LightGBM_top125_nocorr    125             NaN                    125   \n",
       "1             LightGBM_full   1656             NaN                   1656   \n",
       "2    LightGBM_top100_nocorr    100             NaN                    100   \n",
       "3    LightGBM_top150_nocorr    150             NaN                    150   \n",
       "4   LightGBM_top150_corr085    150            0.85                    107   \n",
       "5     LightGBM_top75_nocorr     75             NaN                     75   \n",
       "6   LightGBM_top125_corr085    125            0.85                     91   \n",
       "7    LightGBM_top125_corr08    125            0.80                     82   \n",
       "8    LightGBM_top150_corr09    150            0.90                    114   \n",
       "9     LightGBM_top75_corr08     75            0.80                     54   \n",
       "10   LightGBM_top150_corr08    150            0.80                     93   \n",
       "11    LightGBM_top50_nocorr     50             NaN                     50   \n",
       "12   LightGBM_top125_corr09    125            0.90                     96   \n",
       "13   LightGBM_top100_corr08    100            0.80                     67   \n",
       "14  LightGBM_top100_corr085    100            0.85                     73   \n",
       "15   LightGBM_top100_corr09    100            0.90                     78   \n",
       "16    LightGBM_top75_corr09     75            0.90                     60   \n",
       "17   LightGBM_top75_corr085     75            0.85                     59   \n",
       "18    LightGBM_top50_corr08     50            0.80                     39   \n",
       "19    LightGBM_top50_corr09     50            0.90                     42   \n",
       "20   LightGBM_top50_corr085     50            0.85                     42   \n",
       "21    LightGBM_top25_nocorr     25             NaN                     25   \n",
       "22    LightGBM_top25_corr09     25            0.90                     21   \n",
       "23   LightGBM_top25_corr085     25            0.85                     21   \n",
       "24    LightGBM_top25_corr08     25            0.80                     19   \n",
       "\n",
       "    dropped_corr  business_cost  business_cost_std    recall  recall_std  \\\n",
       "0              0        21301.2         508.261901  0.687460    0.014614   \n",
       "1              0        21311.4         456.538542  0.653852    0.012666   \n",
       "2              0        21371.2         506.202094  0.685043    0.014399   \n",
       "3              0        21387.0         431.447332  0.684468    0.012121   \n",
       "4             43        21394.4         468.647671  0.685907    0.013789   \n",
       "5              0        21422.8         485.753188  0.686194    0.013980   \n",
       "6             34        21426.6         463.434397  0.686425    0.012863   \n",
       "7             43        21450.4         379.764980  0.685849    0.010760   \n",
       "8             36        21462.0         454.315749  0.684583    0.013230   \n",
       "9             21        21476.0         436.334734  0.686655    0.012496   \n",
       "10            57        21489.0         341.360806  0.684238    0.010288   \n",
       "11             0        21491.4         437.361910  0.685791    0.012938   \n",
       "12            29        21502.6         445.274567  0.684410    0.012989   \n",
       "13            33        21513.6         493.015862  0.684871    0.014833   \n",
       "14            27        21523.6         441.376755  0.684410    0.012716   \n",
       "15            22        21532.0         485.151110  0.684468    0.014264   \n",
       "16            15        21555.8         412.759688  0.684526    0.012538   \n",
       "17            16        21575.4         389.295569  0.683950    0.011687   \n",
       "18            11        21669.0         465.698186  0.684295    0.013685   \n",
       "19             8        21671.8         449.442944  0.684583    0.012883   \n",
       "20             8        21671.8         449.442944  0.684583    0.012883   \n",
       "21             0        22067.0         459.380017  0.681072    0.013815   \n",
       "22             4        22317.8         368.118677  0.678253    0.011985   \n",
       "23             4        22317.8         368.118677  0.678253    0.011985   \n",
       "24             6        22397.4         431.221799  0.676584    0.013633   \n",
       "\n",
       "    precision  precision_std        f1    f1_std        f3    f3_std  \\\n",
       "0    0.186234       0.003294  0.293072  0.005371  0.541670  0.010879   \n",
       "1    0.196677       0.003447  0.302392  0.005379  0.530527  0.009920   \n",
       "2    0.185906       0.003357  0.292446  0.005419  0.540042  0.010789   \n",
       "3    0.185844       0.002922  0.292317  0.004667  0.539668  0.009133   \n",
       "4    0.185324       0.002956  0.291803  0.004874  0.540031  0.010125   \n",
       "5    0.184836       0.003123  0.291225  0.005108  0.539778  0.010393   \n",
       "6    0.184723       0.003109  0.291106  0.004986  0.539810  0.009747   \n",
       "7    0.184544       0.002520  0.290831  0.004050  0.539336  0.008042   \n",
       "8    0.184724       0.002902  0.290940  0.004750  0.538784  0.009756   \n",
       "9    0.183956       0.002864  0.290172  0.004619  0.539279  0.009271   \n",
       "10   0.184435       0.002103  0.290551  0.003501  0.538346  0.007451   \n",
       "11   0.183970       0.002729  0.290112  0.004511  0.538811  0.009449   \n",
       "12   0.184190       0.002797  0.290262  0.004620  0.538234  0.009576   \n",
       "13   0.183902       0.003003  0.289945  0.005020  0.538241  0.010734   \n",
       "14   0.183895       0.002862  0.289895  0.004649  0.537980  0.009421   \n",
       "15   0.183754       0.003039  0.289725  0.005022  0.537891  0.010465   \n",
       "16   0.183403       0.002483  0.289293  0.004165  0.537621  0.009009   \n",
       "17   0.183283       0.002370  0.289094  0.003966  0.537201  0.008472   \n",
       "18   0.181875       0.002853  0.287369  0.004761  0.536175  0.010027   \n",
       "19   0.181764       0.002863  0.287256  0.004685  0.536238  0.009556   \n",
       "20   0.181764       0.002863  0.287256  0.004685  0.536238  0.009556   \n",
       "21   0.177291       0.002708  0.281343  0.004571  0.530362  0.009926   \n",
       "22   0.174687       0.001969  0.277818  0.003460  0.526478  0.008218   \n",
       "23   0.174687       0.001969  0.277818  0.003460  0.526478  0.008218   \n",
       "24   0.174049       0.002356  0.276871  0.004117  0.524995  0.009520   \n",
       "\n",
       "         auc   auc_std    time_sec  \n",
       "0   0.782206  0.005061   48.133787  \n",
       "1   0.782745  0.005089  522.616138  \n",
       "2   0.781778  0.005229   32.312829  \n",
       "3   0.781873  0.004765   48.967610  \n",
       "4   0.780311  0.004837   35.949725  \n",
       "5   0.781134  0.005404   20.660311  \n",
       "6   0.780263  0.004775   37.433130  \n",
       "7   0.779741  0.004999   23.562577  \n",
       "8   0.780223  0.005117   40.269654  \n",
       "9   0.778421  0.005188   20.272368  \n",
       "10  0.780007  0.004849   35.184581  \n",
       "11  0.779882  0.005137   16.252551  \n",
       "12  0.780149  0.004541   27.088667  \n",
       "13  0.779401  0.004930   20.772032  \n",
       "14  0.779950  0.004809   32.013798  \n",
       "15  0.779805  0.005173   23.523989  \n",
       "16  0.778823  0.004975   20.586214  \n",
       "17  0.778979  0.005110   31.016258  \n",
       "18  0.776298  0.004859   16.582872  \n",
       "19  0.776758  0.004780   15.752805  \n",
       "20  0.776758  0.004780   22.115781  \n",
       "21  0.770351  0.005320   13.334989  \n",
       "22  0.766274  0.005196   11.968090  \n",
       "23  0.766274  0.005196   15.847871  \n",
       "24  0.765701  0.005033   11.704188  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: c:\\Users\\yoann\\Documents\\open classrooms\\projet 8\\livrables\\pret a dépenser\\reports\\feature_reduction\\feature_reduction_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_red = pd.DataFrame(results_reduction)\n",
    "\n",
    "df_red = df_red.rename(columns={\n",
    "    \"auc_mean\": \"auc\",\n",
    "    \"auc_std\": \"auc_std\",\n",
    "\n",
    "    \"recall_mean_fixed_threshold\": \"recall\",\n",
    "    \"recall_std_fixed_threshold\": \"recall_std\",\n",
    "\n",
    "    \"precision_mean_fixed_threshold\": \"precision\",\n",
    "    \"precision_std_fixed_threshold\": \"precision_std\",\n",
    "\n",
    "    \"f1_mean_fixed_threshold\": \"f1\",\n",
    "    \"f1_std_fixed_threshold\": \"f1_std\",\n",
    "\n",
    "    \"fbeta_3_mean_fixed_threshold\": \"f3\",\n",
    "    \"fbeta_3_std_fixed_threshold\": \"f3_std\",\n",
    "\n",
    "    \"business_cost_mean_fixed_threshold\": \"business_cost\",\n",
    "    \"business_cost_std_fixed_threshold\": \"business_cost_std\",\n",
    "})\n",
    "\n",
    "'''# sécurisation types numériques\n",
    "num_cols = [\"auc\",\"auc_std\",\"recall\",\"recall_std\",\"precision\",\"precision_std\",\"f1\",\"f1_std\",\"f3\",\"f3_std\",\n",
    "            \"business_cost\",\"business_cost_std\",\"time_sec\",\"top_n\",\"n_features_after_corr\",\"dropped_corr\"]\n",
    "for c in num_cols:\n",
    "    if c in df_red.columns:\n",
    "        df_red[c] = pd.to_numeric(df_red[c], errors=\"coerce\")'''\n",
    "\n",
    "# Tri (business_cost plus petit = meilleur)\n",
    "df_red = df_red.sort_values(\n",
    "    by=[\"business_cost\", \"recall\", \"f3\", \"auc\", \"time_sec\"],\n",
    "    ascending=[True, False, False, False, True],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "final_cols = [\n",
    "    \"model\", \"top_n\", \"corr_threshold\", \"n_features_after_corr\", \"dropped_corr\",\n",
    "    \"business_cost\", \"business_cost_std\",\n",
    "    \"recall\", \"recall_std\",\n",
    "    \"precision\", \"precision_std\",\n",
    "    \"f1\", \"f1_std\",\n",
    "    \"f3\", \"f3_std\",\n",
    "    \"auc\", \"auc_std\",\n",
    "    \"time_sec\",\n",
    "]\n",
    "final_cols = [c for c in final_cols if c in df_red.columns]\n",
    "df_final = df_red[final_cols].copy()\n",
    "df_final = df_final.drop_duplicates(subset=[\"model\"]).reset_index(drop=True)\n",
    "display(df_final)\n",
    "\n",
    "out_csv = FEATURE_REDUCTION_DIR / \"feature_reduction_results.csv\"\n",
    "df_final.to_csv(out_csv, index=False)\n",
    "print(\"CSV:\", out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925cdf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run summary MLflow créé\n",
      "\n",
      "=== Conclusion auto (meilleur compromis) ===\n",
      "Modèle : LightGBM_top125_nocorr\n",
      "Nb variables : 125\n",
      "Coût métier : 21301.2\n",
      "Recall : 0.687460241243139\n",
      "F3 : 0.5416703548589556\n",
      "AUC : 0.7822058984653175\n",
      "Temps (s) : 48.13378715515137\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "with mlflow.start_run(run_name=f\"LightGBM_feature_reduction_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "    mlflow.set_tag(\"phase\", \"feature_reduction_summary\")\n",
    "    mlflow.set_tag(\"model_name\", \"LightGBM\")\n",
    "    mlflow.set_tag(\"dataset\", \"train_split\")\n",
    "    mlflow.set_tag(\"threshold_mode\", \"fixed\")\n",
    "    mlflow.set_tag(\"threshold_fixed\", str(float(THRESH_FIXED)))\n",
    "    mlflow.set_tag(\"cost_fn\", str(int(COST_FN)))\n",
    "    mlflow.set_tag(\"cost_fp\", str(int(COST_FP)))\n",
    "    mlflow.set_tag(\"fbeta_beta\", str(float(FBETA_BETA)))\n",
    "\n",
    "    mlflow.log_artifact(str(out_csv))\n",
    "\n",
    "    best = df_final.iloc[0]\n",
    "\n",
    "    # tags best\n",
    "    mlflow.set_tag(\"best.model\", str(best.get(\"model\", \"\")))\n",
    "    mlflow.set_tag(\"best.top_n\", str(int(best.get(\"top_n\", -1))))\n",
    "    if pd.notna(best.get(\"corr_threshold\", np.nan)):\n",
    "        mlflow.set_tag(\"best.corr_threshold\", str(float(best[\"corr_threshold\"])))\n",
    "    else:\n",
    "        mlflow.set_tag(\"best.corr_threshold\", \"none\")\n",
    "    mlflow.set_tag(\"best.n_features_after_corr\", str(int(best.get(\"n_features_after_corr\", -1))))\n",
    "    mlflow.set_tag(\"best.dropped_corr\", str(int(best.get(\"dropped_corr\", 0))))\n",
    "\n",
    "    # metrics best\n",
    "    for k in [\"business_cost\",\"business_cost_std\",\"recall\",\"recall_std\",\"precision\",\"precision_std\",\n",
    "              \"f1\",\"f1_std\",\"f3\",\"f3_std\",\"auc\",\"auc_std\",\"time_sec\"]:\n",
    "        if k in best and pd.notna(best[k]):\n",
    "            mlflow.log_metric(f\"best_{k}\", float(best[k]))\n",
    "\n",
    "print(\"Run summary MLflow créé\")\n",
    "\n",
    "# --- Conclusion auto (print) ---\n",
    "best = df_final.iloc[0]\n",
    "print(\"\\n=== Conclusion auto (meilleur compromis) ===\")\n",
    "print(\"Modèle :\", best[\"model\"])\n",
    "print(\"Nb variables :\", int(best[\"n_features_after_corr\"]))\n",
    "print(\"Coût métier :\", float(best[\"business_cost\"]))\n",
    "print(\"Recall :\", float(best[\"recall\"]))\n",
    "print(\"F3 :\", float(best[\"f3\"]))\n",
    "print(\"AUC :\", float(best[\"auc\"]))\n",
    "print(\"Temps (s) :\", float(best[\"time_sec\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a144b3",
   "metadata": {},
   "source": [
    "## Conclusion – Réduction de périmètre (LightGBM)\n",
    "\n",
    "La comparaison des modèles réduits a été réalisée en priorisant le **coût métier** (FN ×10 + FP ×1), calculé à **seuil fixe 0.5**, via validation croisée.\n",
    "\n",
    "Le meilleur compromis est obtenu avec **LightGBM_top125_nocorr** (125 variables) :\n",
    "\n",
    "- **Coût métier** : 21 301 (meilleur, et légèrement inférieur au modèle complet)\n",
    "- **Recall** : 0.687 (supérieur au modèle complet à 0.654)\n",
    "- **F3** : 0.542 (supérieur au modèle complet à 0.531)\n",
    "- **AUC** : 0.782 (équivalente au modèle complet à 0.783)\n",
    "- **Temps d’entraînement** : ~64 s (contre ~915 s pour le modèle complet)\n",
    "\n",
    "La réduction du périmètre permet donc de conserver la performance globale tout en améliorant les indicateurs métier et en réduisant fortement le temps de calcul.\n",
    "\n",
    "Le **filtrage par corrélation** accélère encore l’entraînement, mais n’apporte pas de gain sur le coût métier par rapport au meilleur modèle sans filtrage.  \n",
    "Le modèle retenu pour la suite est donc **LightGBM_top125_nocorr**, base de travail pour l’optimisation du seuil métier et l’interprétabilité (SHAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabdf51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock saved: c:\\Users\\yoann\\Documents\\open classrooms\\projet 8\\livrables\\pret a dépenser\\reports\\feature_reduction\\dataset_lock.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "lock = {\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"dataset\": \"train_split.csv\",\n",
    "    \"best_model\": \"LightGBM_top125_nocorr\",\n",
    "    \"feature_file\": \"kept_features_top125_nocorr.txt\",\n",
    "    \"cv\": 5,\n",
    "    \"random_state\": 42,\n",
    "    \"threshold_fixed\": 0.5,\n",
    "    \"cost_fn\": 10,\n",
    "    \"cost_fp\": 1,\n",
    "    \"fbeta_beta\": 3,\n",
    "}\n",
    "\n",
    "lock_path = FEATURE_REDUCTION_DIR / \"dataset_lock.json\"\n",
    "lock_path.write_text(json.dumps(lock, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"Lock saved:\", lock_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
