{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591aebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from modeling.prepare_for_model import prepare_application_for_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be96b092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = C:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\n",
      "DB exists ? False\n",
      "ARTIFACT_ROOT exists ? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Racine projet\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\")\n",
    "DB_PATH = PROJECT_ROOT / \"mlflow.db\"\n",
    "ARTIFACT_ROOT = PROJECT_ROOT / \"artifacts\"\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"DB exists ?\", DB_PATH.exists())\n",
    "print(\"ARTIFACT_ROOT exists ?\", ARTIFACT_ROOT.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90bd0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI = sqlite:///C:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\\mlflow.db\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(f\"sqlite:///{DB_PATH}\")\n",
    "\n",
    "print(\"Tracking URI =\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f670f2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/19 11:06:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/19 11:06:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2026/01/19 11:06:56 INFO mlflow.tracking.fluent: Experiment with name 'home_credit_tracking' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment actif = home_credit_tracking\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"home_credit_tracking\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(\"Experiment actif =\", mlflow.get_experiment_by_name(EXPERIMENT_NAME).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98602bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (215257, 1769)\n",
      "Test : (46127, 1769)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(PROJECT_ROOT / \"data\" / \"processed\" / \"train_final.csv\")\n",
    "\n",
    "from modeling.prepare_for_model import prepare_application_for_model\n",
    "\n",
    "X, y = prepare_application_for_model(df, model_type=\"boosting\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8acb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1664c416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.469100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 243802\n",
      "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 1764\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/19 11:10:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run terminé\n",
      "AUC   = 0.7851806358167359\n",
      "Recall= 0.6501074113856069\n",
      "F1    = 0.30945229117402695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run(run_name=\"tracking_test_lgbm\"):\n",
    "\n",
    "    # Entraînement\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédictions\n",
    "    preds_proba = model.predict_proba(X_test)[:, 1]\n",
    "    preds_class = (preds_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Métriques\n",
    "    auc = roc_auc_score(y_test, preds_proba)\n",
    "    recall = recall_score(y_test, preds_class)\n",
    "    f1 = f1_score(y_test, preds_class)\n",
    "\n",
    "    # Logs\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"LightGBM\",\n",
    "        \"n_estimators\": 200,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64\n",
    "    })\n",
    "\n",
    "    mlflow.set_tag(\"stage\", \"tracking_test\")\n",
    "    mlflow.set_tag(\"dataset\", \"train_final\")\n",
    "\n",
    "    # Sauvegarde modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    print(\"Run terminé\")\n",
    "    print(\"AUC   =\", auc)\n",
    "    print(\"Recall=\", recall)\n",
    "    print(\"F1    =\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71028ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment id = 1\n",
      "Artifact location = file:///c:/Users/yoann/Documents/open classrooms/projet 6/pret a depenser v2/notebooks/mlruns/1\n",
      "Nombre de runs = 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "print(\"Experiment id =\", exp.experiment_id)\n",
    "print(\"Artifact location =\", exp.artifact_location)\n",
    "\n",
    "runs = client.search_runs([exp.experiment_id])\n",
    "print(\"Nombre de runs =\", len(runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
