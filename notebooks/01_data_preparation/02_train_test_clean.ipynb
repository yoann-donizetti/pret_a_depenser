{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fc9b69",
   "metadata": {},
   "source": [
    "# Préprocessing Baseline (minimal + pipeline-ready)\n",
    "**Objectif** : corrections déterministes + export datasets \"base\".\n",
    "Tout ce qui dépend des stats (médiane/mode, etc.) sera fait dans le pipeline sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c8d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_PATH = c:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\\data\\raw\\application_train.csv\n",
      "TEST_PATH  = c:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\\data\\raw\\application_test.csv\n",
      "(307511, 122) (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "\n",
    "# Racine du projet\n",
    "CWD = Path.cwd()\n",
    "PROJECT_ROOT = CWD.parent.parent \n",
    "\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "TRAIN_PATH = DATA_RAW / \"application_train.csv\"\n",
    "TEST_PATH  = DATA_RAW / \"application_test.csv\"\n",
    "\n",
    "print(\"TRAIN_PATH =\", TRAIN_PATH)\n",
    "print(\"TEST_PATH  =\", TEST_PATH)\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649d352",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires “déterministes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b8666",
   "metadata": {},
   "source": [
    "### Détection colonnes binaires + mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2f75d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y/N: 2  | 0/1: 32\n"
     ]
    }
   ],
   "source": [
    "def find_binary_columns(df: pd.DataFrame):\n",
    "    # Y/N binaires\n",
    "    binary_yn = [\n",
    "        c for c in df.columns\n",
    "        if df[c].dtype == \"object\"\n",
    "        and set(df[c].dropna().unique()) <= {\"Y\", \"N\"}\n",
    "    ]\n",
    "\n",
    "    # 0/1 binaires (attention: exclure TARGET plus tard)\n",
    "    binary_01 = [\n",
    "        c for c in df.columns\n",
    "        if df[c].nunique(dropna=True) == 2\n",
    "        and set(df[c].dropna().unique()) <= {0, 1}\n",
    "    ]\n",
    "    return binary_yn, binary_01\n",
    "\n",
    "\n",
    "def apply_binary_mapping(train: pd.DataFrame, test: pd.DataFrame, target_col=\"TARGET\"):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "\n",
    "    bin_yn, bin_01 = find_binary_columns(train)\n",
    "    bin_01 = [c for c in bin_01 if c != target_col]\n",
    "\n",
    "    # Y/N -> bool\n",
    "    for c in bin_yn:\n",
    "        train[c] = train[c].map({\"Y\": True, \"N\": False})\n",
    "        test[c]  = test[c].map({\"Y\": True, \"N\": False})\n",
    "\n",
    "    # 0/1 -> bool\n",
    "    for c in bin_01:\n",
    "        # safe cast si jamais c'est float avec 0/1\n",
    "        train[c] = train[c].astype(\"Int64\").astype(\"boolean\")\n",
    "        test[c]  = test[c].astype(\"Int64\").astype(\"boolean\")\n",
    "\n",
    "    return train, test, {\"binary_yn\": bin_yn, \"binary_01\": bin_01}\n",
    "\n",
    "\n",
    "train, test, bin_info = apply_binary_mapping(train, test)\n",
    "print(\"Y/N:\", len(bin_info[\"binary_yn\"]), \" | 0/1:\", len(bin_info[\"binary_01\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ba712",
   "metadata": {},
   "source": [
    "## Correction des sentinelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29d3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sentinels(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "\n",
    "    # 1) DAYS_EMPLOYED sentinel\n",
    "    if \"DAYS_EMPLOYED\" in train.columns:\n",
    "        sentinel = 365243\n",
    "\n",
    "        train[\"FLAG_DAYS_EMPLOYED_SENTINEL\"] = (train[\"DAYS_EMPLOYED\"] == sentinel).astype(\"int8\")\n",
    "        test[\"FLAG_DAYS_EMPLOYED_SENTINEL\"]  = (test[\"DAYS_EMPLOYED\"] == sentinel).astype(\"int8\")\n",
    "\n",
    "        train.loc[train[\"DAYS_EMPLOYED\"] == sentinel, \"DAYS_EMPLOYED\"] = np.nan\n",
    "        test.loc[test[\"DAYS_EMPLOYED\"] == sentinel, \"DAYS_EMPLOYED\"] = np.nan\n",
    "\n",
    "    # 2) Catégorielles \"XNA\" / \"XAP\" (souvent = manquant codé)\n",
    "    cat_cols = train.select_dtypes(include=[\"object\"]).columns\n",
    "    for c in cat_cols:\n",
    "        train[c] = train[c].replace({\"XNA\": np.nan, \"XAP\": np.nan})\n",
    "        test[c]  = test[c].replace({\"XNA\": np.nan, \"XAP\": np.nan})\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = fix_sentinels(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09952177",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Controle alignement train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e45822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes train absentes test: 0\n",
      "Colonnes test absentes train: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TARGET_COL = \"TARGET\"\n",
    "\n",
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "\n",
    "# test n'a pas TARGET\n",
    "missing_in_test = sorted(list(train_cols - test_cols - {TARGET_COL}))\n",
    "extra_in_test = sorted(list(test_cols - train_cols))\n",
    "\n",
    "print(\"Colonnes train absentes test:\", len(missing_in_test))\n",
    "print(\"Colonnes test absentes train:\", len(extra_in_test))\n",
    "\n",
    "# normalement 0 et 0 (hors TARGET)\n",
    "if missing_in_test:\n",
    "    print(\"Exemples missing_in_test:\", missing_in_test[:10])\n",
    "if extra_in_test:\n",
    "    print(\"Exemples extra_in_test:\", extra_in_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275095eb",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57dc4238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\\data\\processed\\application_train_base.csv\n",
      "Saved: c:\\Users\\yoann\\Documents\\open classrooms\\projet 6\\pret a depenser v2\\data\\processed\\application_test_base.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUT_TRAIN = DATA_PROCESSED / \"application_train_base.csv\"\n",
    "OUT_TEST  = DATA_PROCESSED / \"application_test_base.csv\"\n",
    "\n",
    "train.to_csv(OUT_TRAIN, index=False)\n",
    "test.to_csv(OUT_TEST, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_TRAIN)\n",
    "print(\"Saved:\", OUT_TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
